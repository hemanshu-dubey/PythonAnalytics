{"cells":[{"cell_type":"code","source":["sales_data = spark.read.csv('/FileStore/tables/mzzox8571489588748655/Predictor_variables_raw.csv', header=True, inferSchema=True)"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["sales_data.show(5)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#rdd consist of row objects\n#x is Row object\nsales_data.select('sales').rdd.map(lambda x: x.sales).count()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Applying map on a specific col\nsales_data.select('sales').rdd.map(lambda x: x.sales).collect()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["sales_data.withColumn('new_sales', sales_data.sales * 2).select('sales','new_sales').show()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["sales_data = sales_data.withColumn('n_sales', sales_data.sales*2)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["sales_data.show(5)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from pyspark.sql import Row\nd = sales_data.select('sales').rdd.map(lambda x: Row(abc=x.sales,defg=100)).toDF()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#You can create dataframe using list of tuple of list of lists\nd.show()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["sales_data.select('sales').collect()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":11}],"metadata":{"name":"DataFrame Manupulation","notebookId":4205992444275021},"nbformat":4,"nbformat_minor":0}
