{"cells":[{"cell_type":"code","source":["import argparse\nimport re\n\nfrom pyspark.sql import SparkSession\n\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.regression import RandomForestRegressor, RandomForestRegressionModel\nfrom pyspark.ml import Pipeline, PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.mllib.evaluation import RegressionMetrics"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#/FileStore/tables/cb1iklgz1490855926352/test.csv\n#/FileStore/tables/cb1iklgz1490855926352/train.csv"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["trainInput = spark.read.csv('/FileStore/tables/cb1iklgz1490855926352/train.csv',header=True, inferSchema=True)\ntestInput = spark.read.csv('/FileStore/tables/cb1iklgz1490855926352/test.csv', header=True, inferSchema=True)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["display(trainInput)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["def setParams():\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\"--trainInput\",  help=\"Path to file/directory for training data\", required=True)\n  parser.add_argument(\"--testInput\",   help=\"Path to file/directory for test data\", required=True)\n  parser.add_argument(\"--outputFile\",  help=\"Path to output file\")\n  parser.add_argument(\"--algoNumTrees\", nargs='+', type=int, help=\"One or more options for number of trees for RandomForest model. Default: 3\", default=[3])\n  parser.add_argument(\"--algoMaxDepth\", nargs='+', type=int, help=\"One or more values for depth limit. Default: 4\", default=[4])\n  parser.add_argument(\"--algoMaxBins\",  nargs='+', type=int, help=\"One or more values for max bins for RandomForest model. Default: 32\", default=[32])\n  parser.add_argument(\"--numFolds\",    type=int,   help=\"Number of folds for K-fold Cross Validation. Default: 10\", default=10)\n  parser.add_argument(\"--trainSample\", type=float, help=\"Sample fraction from 0.0 to 1.0 for train data\", default=1.0)\n  parser.add_argument(\"--testSample\",  type=float, help=\"Sample fraction from 0.0 to 1.0 for test data\", default=1.0)\n\n  params = parser.parse_args()\n  return params"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#params = setParams() \ndata = (trainInput.withColumnRenamed(\"loss\", \"label\"))\n[trainingData, validationData] = data.randomSplit([0.7, 0.3])\n\ntrainingData.cache()\nvalidationData.cache()\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#******************************************\nprint(\"Building Machine Learning pipeline\")\n#******************************************\n\n    #StringIndexer for categorical columns (OneHotEncoder should be evaluated as well)\nisCateg     = lambda c: c.startswith(\"cat\")\ncategNewCol = lambda c: \"idx_{0}\".format(c) if (isCateg(c)) else c\n\nstringIndexerStages = map(lambda c: StringIndexer(inputCol=c, outputCol=categNewCol(c))\n.fit(trainInput.select(c).union(testInput.select(c))), filter(isCateg, trainingData.columns))\n\n    #Function to remove categorical columns with too many categories\nremoveTooManyCategs = lambda c: not re.match(r\"cat(109$|110$|112$|113$|116$)\", c)\n\n    #Function to select only feature columns (omit id and label)\nonlyFeatureCols = lambda c: not re.match(r\"id|label\", c)\n\n    #Definitive set of feature columns\nfeatureCols = map(categNewCol, \n                      filter(onlyFeatureCols, \n                             filter(removeTooManyCategs, \n                                    trainingData.columns)))\n\n    #VectorAssembler for training features\nassembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\")\n\n    #Estimator algorithm\nalgo = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")\n    \nstages = stringIndexerStages\nstages.append(assembler)\nstages.append(algo)\n\n    #Building the Pipeline for transformations and predictor\npipeline = Pipeline(stages=stages)\n\n\n    #*********************************************************\nprint(\"Preparing K-fold Cross Validation and Grid Search\")\n    #*********************************************************\n\nparamGrid = (ParamGridBuilder()\n     .addGrid(algo.numTrees, [3])\n     .addGrid(algo.maxDepth, [4])\n     .addGrid(algo.maxBins, [32])\n     .build())\n      \ncv = CrossValidator(estimator=pipeline,\n                        evaluator=RegressionEvaluator(),\n                        estimatorParamMaps=paramGrid,\n                        numFolds=10)\n\n\n    #**********************************************************\nprint(\"Training model with RandomForest algorithm\")\n    #**********************************************************\n\ncvModel = cv.fit(trainingData)\n\n\n    #********************************************************************\nprint(\"Evaluating model on train and test data and calculating RMSE\")\n    #********************************************************************\n    \ntrainPredictionsAndLabels = cvModel.transform(trainingData).select(\"label\", \"prediction\").rdd\n\nvalidPredictionsAndLabels = cvModel.transform(validationData).select(\"label\", \"prediction\").rdd\n\ntrainRegressionMetrics = RegressionMetrics(trainPredictionsAndLabels)\nvalidRegressionMetrics = RegressionMetrics(validPredictionsAndLabels)\n\nbestModel = cvModel.bestModel\nfeatureImportances = bestModel.stages[-1].featureImportances.toArray()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["output = (\"\\n=====================================================================\\n\" +\n#       \"Param trainSample: {0}\\n\".format(params.trainSample) +\n#       \"Param testSample: {0}\\n\".format(params.testSample) +\n#       \"TrainingData count: {0}\\n\".format(trainingData.count()) +\n#       \"ValidationData count: {0}\\n\".format(validationData.count()) +\n#       \"TestData count: {0}\\n\".format(testData.count()) +\n#       \"=====================================================================\\n\" +\n#       \"Param algoNumTrees = {0}\\n\".format(\",\".join(params.algoNumTrees)) +\n#       \"Param algoMaxDepth = {0}\\n\".format(\",\".join(params.algoMaxDepth)) +\n#       \"Param algoMaxBins = {0}\\n\".format(\",\".join(params.algoMaxBins)) +\n#       \"Param numFolds = {0}\\n\".format(params.numFolds) +\n      \"=====================================================================\\n\" +\n      \"Training data MSE = {0}\\n\".format(trainRegressionMetrics.meanSquaredError) +\n      \"Training data RMSE = {0}\\n\".format(trainRegressionMetrics.rootMeanSquaredError) +\n      \"Training data R-squared = {0}\\n\".format(trainRegressionMetrics.r2) +\n      \"Training data MAE = {0}\\n\".format(trainRegressionMetrics.meanAbsoluteError) +\n      \"Training data Explained variance = {0}\\n\".format(trainRegressionMetrics.explainedVariance) +\n      \"=====================================================================\\n\" +\n      \"Validation data MSE = {0}\\n\".format(validRegressionMetrics.meanSquaredError) +\n      \"Validation data RMSE = {0}\\n\".format(validRegressionMetrics.rootMeanSquaredError) +\n      \"Validation data R-squared = {0}\\n\".format(validRegressionMetrics.r2) +\n      \"Validation data MAE = {0}\\n\".format(validRegressionMetrics.meanAbsoluteError) +\n      \"Validation data Explained variance = {0}\\n\".format(validRegressionMetrics.explainedVariance) +\n      \"=====================================================================\\n\" +\n      # \"CV params explained: ${cvModel.explainParams()}\\n\" +\n      # \"RandomForest params explained: ${bestModel.stages[-1].explainParams()}\\n\" +\n      \"RandomForest features importances:\\n {0}\\n\".format(\"\\n\".join(map(lambda z: \"{0} = {1}\".format(str(z[0]),str(z[1])), zip(featureCols, featureImportances)))) +\n      \"=====================================================================\\n\")\nprint(output)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["display(cvModel.transform(testInput).select(\"id\", \"prediction\"))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"Allstate Claims Severity","notebookId":1282604075163212},"nbformat":4,"nbformat_minor":0}
