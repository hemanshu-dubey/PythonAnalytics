{"cells":[{"cell_type":"markdown","source":["<h1>Predict chances of infant survival with Spark ML</h1>"],"metadata":{}},{"cell_type":"markdown","source":["<h3>Schema Prep and Data Loading</h3>"],"metadata":{}},{"cell_type":"code","source":["import pyspark.sql.types as typ\n\nlabels = [\n    ('INFANT_ALIVE_AT_REPORT', typ.IntegerType()),\n    ('BIRTH_PLACE', typ.StringType()),\n    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n    ('CIG_BEFORE', typ.IntegerType()),\n    ('CIG_1_TRI', typ.IntegerType()),\n    ('CIG_2_TRI', typ.IntegerType()),\n    ('CIG_3_TRI', typ.IntegerType()),\n    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n    ('DIABETES_PRE', typ.IntegerType()),\n    ('DIABETES_GEST', typ.IntegerType()),\n    ('HYP_TENS_PRE', typ.IntegerType()),\n    ('HYP_TENS_GEST', typ.IntegerType()),\n    ('PREV_BIRTH_PRETERM', typ.IntegerType())\n]\n\n#creating list of StructField that eventually becomes schema\n\nschema = typ.StructType([ typ.StructField(e[0], e[1], False) for e in labels ])\n\nbirths = spark.read.csv('/FileStore/tables/m10h45tz1490702575759/births_transformed_csv-da688.gz', \n                        header=True, \n                        schema=schema)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["display(births)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["<h3>Create Transformers</h3>"],"metadata":{}},{"cell_type":"code","source":["import pyspark.ml.feature as ft\n\nbirths = births \\\n    .withColumn(       'BIRTH_PLACE_INT', \n                births['BIRTH_PLACE'] \\\n                    .cast(typ.IntegerType()))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["births.columns"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(births)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["births.printSchema()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["<p>Having done this, we can now create our first Transformer.</p>"],"metadata":{}},{"cell_type":"code","source":["#Algo will take all possible words - UP MP AP GUJ AS\n[0,1,0,0,0]\n\nencoder = ft.OneHotEncoder(\n    inputCol='BIRTH_PLACE_INT', \n    outputCol='BIRTH_PLACE_VEC')"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["<p>Let's now create a single column with all the features collated together.</p>"],"metadata":{}},{"cell_type":"code","source":["# Understanding VectorAssembler\ndf = spark.createDataFrame([(12,3,4),(10,5,6)], ['a','b','c'])\n#display(df)\ndisplay(ft.VectorAssembler(inputCols=['a','b','c'], outputCol='features').transform(df))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Transforms multiple numeric columns into a single column with vector representation\nfeaturesCreator = ft.VectorAssembler(\n    inputCols=[\n        col[0] \n        for col \n        in labels[2:]] + \\\n    [encoder.getOutputCol()], \n    outputCol='features'\n)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["<h3>Create an estimator</h3>"],"metadata":{}},{"cell_type":"code","source":["import pyspark.ml.classification as cl\n# Create a model\n\nlogistic = cl.LogisticRegression(\n    maxIter=10, \n    regParam=0.01, \n    labelCol='INFANT_ALIVE_AT_REPORT')"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["<h3>Create a pipleline</h3>\n\n<p>All that is left now is to creat a Pipeline and fit the model. First, let's load the Pipeline from the package.</p>"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[\n        encoder,            #Creates a new df with one additional column - birth_place_int\n        featuresCreator,    #Feature vector needs to be created so that estimator can create model - from multiple col to single col \n        logistic            #logistic take input of one vector\n    ])"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["<h3>Fit the model </h3>\n<p>Split data into train and test model</p>"],"metadata":{}},{"cell_type":"code","source":["births_train, births_test = births \\\n    .randomSplit([0.7, 0.3], seed=666)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["<p>Run pipeline and estimate model</p>"],"metadata":{}},{"cell_type":"code","source":["model = pipeline.fit(births_train)\ntest_model = model.transform(births_test)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["test_model.take(1)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["<h3>Model performance</h3>\n<p>Checking model performanace</p>"],"metadata":{}},{"cell_type":"code","source":["import pyspark.ml.evaluation as ev\n\nevaluator = ev.BinaryClassificationEvaluator(\n    rawPredictionCol='probability', \n    labelCol='INFANT_ALIVE_AT_REPORT')\n\nprint(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderROC'}))\nprint(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderPR'}))"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["<h2>Persistance - Saving the pipeline and model</h2>\n<p>PySpark allows you to save the Pipeline definition for later use.</p>"],"metadata":{}},{"cell_type":"code","source":["pipelinePath = '/FileStore/tables/m10h45tz1490702575759/infant_oneHotEncoder_Logistic_Pipeline'\npipeline.write().overwrite().save(pipelinePath)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["<p>load it up later and use straight away to .fit(...) and predict.</p>"],"metadata":{}},{"cell_type":"code","source":["loadedPipeline = Pipeline.load(pipelinePath)\nloadedPipeline \\\n    .fit(births_train)\\\n    .transform(births_test)\\\n    .take(1)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["from pyspark.ml import PipelineModel\n\nmodelPath = '/FileStore/tables/m10h45tz1490702575759/infant_oneHotEncoder_Logistic_PipelineModel'\nmodel.write().overwrite().save(modelPath)\n\nloadedPipelineModel = PipelineModel.load(modelPath)\n# Now, predicting for test dataset\ntest_loadedModel = loadedPipelineModel.transform(births_test)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["<h2>Parameter hyper-tuning</h2>"],"metadata":{}},{"cell_type":"code","source":["import pyspark.ml.tuning as tune\nlogistic = cl.LogisticRegression(\n    labelCol='INFANT_ALIVE_AT_REPORT')\n\ngrid = tune.ParamGridBuilder() \\\n    .addGrid(logistic.maxIter,  \n             [2, 10, 50]) \\\n    .addGrid(logistic.regParam, \n             [0.01, 0.05, 0.3]) \\\n    .build()"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["evaluator = ev.BinaryClassificationEvaluator(\n    rawPredictionCol='probability', \n    labelCol='INFANT_ALIVE_AT_REPORT')"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["cv = tune.CrossValidator(\n    estimator=logistic, \n    estimatorParamMaps=grid, \n    evaluator=evaluator\n)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["pipeline = Pipeline(stages=[encoder,featuresCreator])\ndata_transformer = pipeline.fit(births_train)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["cvModel = cv.fit(data_transformer.transform(births_train))"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["data_train = data_transformer \\\n    .transform(births_test)\nresults = cvModel.transform(data_train)\n\nprint(evaluator.evaluate(results, \n     {evaluator.metricName: 'areaUnderROC'}))\nprint(evaluator.evaluate(results, \n     {evaluator.metricName: 'areaUnderPR'}))"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["results"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["sorted(results, key=lambda el: el[1], reverse=True)[0]"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["selector = ft.ChiSqSelector(\n    numTopFeatures=5, \n    featuresCol=featuresCreator.getOutputCol(), \n    outputCol='selectedFeatures',\n    labelCol='INFANT_ALIVE_AT_REPORT'\n)\n\nlogistic = cl.LogisticRegression(\n    labelCol='INFANT_ALIVE_AT_REPORT',\n    featuresCol='selectedFeatures'\n)\n\npipeline = Pipeline(stages=[encoder,featuresCreator,selector])\ndata_transformer = pipeline.fit(births_train)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["tvs = tune.TrainValidationSplit(\n    estimator=logistic, \n    estimatorParamMaps=grid, \n    evaluator=evaluator\n)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["tvsModel = tvs.fit(\n    data_transformer \\\n        .transform(births_train)\n)\n\ndata_train = data_transformer \\\n    .transform(births_test)\nresults = tvsModel.transform(data_train)\n\nprint(evaluator.evaluate(results, \n     {evaluator.metricName: 'areaUnderROC'}))\nprint(evaluator.evaluate(results, \n     {evaluator.metricName: 'areaUnderPR'}))"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":43}],"metadata":{"name":"Infant Survival using Spark ML","notebookId":3208808890570308},"nbformat":4,"nbformat_minor":0}
