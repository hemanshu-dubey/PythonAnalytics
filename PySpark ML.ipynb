{"cells":[{"cell_type":"code","source":["from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.classification import LogisticRegression"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["training = spark.createDataFrame([\n    (1.0, Vectors.dense([0.0, 1.1, 0.1])),\n    (0.0, Vectors.dense([2.0, 1.0, -1.0])),\n    (0.0, Vectors.dense([2.0, 1.3, 1.0])),\n    (1.0, Vectors.dense([0.0, 1.2, -0.5]))], [\"label\", \"features\"])"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["training.show()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Create a LogisticRegression instance. This instance is an Estimator.\nlr = LogisticRegression(maxIter=10, regParam=0.01)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["lr.explainParams()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Learn a LogisticRegression model. This uses the parameters stored in lr.\nmodel1 = lr.fit(training)\n# this is the transformer produced by Estimator()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Prepare test data\ntest = spark.createDataFrame([\n    (1.0, Vectors.dense([-1.0, 1.5, 1.3])),\n    (0.0, Vectors.dense([3.0, 2.0, -0.1])),\n    (1.0, Vectors.dense([0.0, 2.2, -1.5]))], [\"label\", \"features\"])"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["prediction = model1.transform(test)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["prediction.show()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["model1.extractParamMap()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# parameters are init values\nparamMap = {lr.maxIter: 20}\nparamMap.update({lr.regParam: 0.1, lr.threshold: 0.55})\n\nparamMap"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# You can combine paramMaps, which are python dictionaries.\nparamMap2 = {lr.probabilityCol: \"myProbability\"}  # Change output column name\nparamMapCombined = paramMap.copy()\nparamMapCombined.update(paramMap2)\n\nparamMapCombined"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["model2 = lr.fit(training, paramMapCombined)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["model2.extractParamMap()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# Prepare training documents from a list of (id, text, label) tuples.\ntraining = spark.createDataFrame([\n    (0, \"a b c d e spark\", 1.0),\n    (1, \"b d\", 0.0),\n    (2, \"spark f g h\", 1.0),\n    (3, \"hadoop mapreduce\", 0.0)\n], [\"id\", \"text\", \"label\"])"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["training.show()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["lr = LogisticRegression(maxIter=10, regParam=0.001)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n\nmodel = pipeline.fit(training)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["test = spark.createDataFrame([\n    (4, \"spark i j k\"),\n    (5, \"l m n\"),\n    (6, \"spark hadoop spark\"),\n    (7, \"apache hadoop\")\n], [\"id\", \"text\"])"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["pred = model.transform(test)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["pred.show()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":24}],"metadata":{"name":"PySpark ML","notebookId":3761516330363965},"nbformat":4,"nbformat_minor":0}
